import tkinter as tk
from tkinter import filedialog, messagebox
from PIL import Image, ImageTk
import cv2
import subprocess
import threading
import os
import numpy as np
import pickle
import face_recognition
import time






class FaceRecognitionApp:
    def __init__(self, root):
        self.root = root
        self.root.title("Face Recognition System")
        self.root.geometry("1200x700")
        self.root.resizable(False, False)

        self.video_capture = None
        self.running = False

        self.build_ui()
        self.data = None
        self.load_model()

        self.mode = "idle"   # idle | collect | realtime
        self.last_save_time = 0
        self.save_interval = 1  # —Å–µ–∫—É–Ω–¥
        self.face_counter = 0

        # Haar Cascade
        cascPath = cv2.data.haarcascades + "haarcascade_frontalface_alt2.xml"
        self.faceCascade = cv2.CascadeClassifier(cascPath)
        



    def build_ui(self):
        # ===== –õ–ï–í–ê–Ø –ü–ê–ù–ï–õ–¨ =====
        control_frame = tk.Frame(self.root, width=350, bg="#f0f0f0")
        control_frame.pack(side=tk.LEFT, fill=tk.Y)

        # === –°–±–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞ ===
        tk.Label(control_frame, text="–°–±–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞", font=("Arial", 12, "bold")).pack(pady=5)

        tk.Label(control_frame, text="–ò–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è:").pack()
        self.username_entry = tk.Entry(control_frame)
        self.username_entry.insert(0, "User1")
        self.username_entry.pack(pady=5)

        tk.Button(control_frame, text="‚ñ∂ –ù–∞—á–∞—Ç—å —Å–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö", command=self.collect_dataset).pack(pady=5)

        # === –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ ===
        tk.Label(control_frame, text="–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏", font=("Arial", 12, "bold")).pack(pady=10)
        tk.Button(control_frame, text="‚úè –û–±—É—á–∏—Ç—å –Ω–∞ –¥–∞—Ç–∞—Å–µ—Ç–µ", command=self.train_model).pack(pady=5)

        # === –§–æ—Ç–æ ===
        tk.Label(control_frame, text="–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –ø–æ —Ñ–æ—Ç–æ", font=("Arial", 12, "bold")).pack(pady=10)
        tk.Button(control_frame, text="üìÅ –í—ã–±—Ä–∞—Ç—å –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ñ–æ—Ç–æ", command=self.recognize_photo).pack(pady=5)

        # === Real-time ===
        tk.Label(control_frame, text="–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏", font=("Arial", 12, "bold")).pack(pady=10)
        tk.Button(control_frame, text="‚ñ∂ –°—Ç–∞—Ä—Ç —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è", command=self.start_realtime).pack(pady=5)
        tk.Button(control_frame, text="‚ñ† –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å", command=self.stop_realtime).pack(pady=5)

        # === –°—Ç–∞—Ç—É—Å ===
        tk.Label(control_frame, text="–°—Ç–∞—Ç—É—Å", font=("Arial", 12, "bold")).pack(pady=10)
        self.status_label = tk.Label(control_frame, text="–†–µ–∂–∏–º: –û–∂–∏–¥–∞–Ω–∏–µ")
        self.status_label.pack(pady=5)

        # ===== –ü–†–ê–í–ê–Ø –ü–ê–ù–ï–õ–¨ =====
        display_frame = tk.Frame(self.root, bg="black")
        display_frame.pack(side=tk.RIGHT, expand=True, fill=tk.BOTH)

        self.video_label = tk.Label(display_frame, bg="black")
        self.video_label.pack(expand=True)

        self.show_text("–í—ã–±–µ—Ä–∏—Ç–µ —Ä–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤–∏–¥–µ–æ")

    # ===== –§–£–ù–ö–¶–ò–ò =====

    def show_text(self, text):
        img = Image.new("RGB", (800, 600), "black")
        self.video_img = ImageTk.PhotoImage(img)
        self.video_label.config(image=self.video_img)
        self.video_label.config(text=text, fg="white", font=("Arial", 16))

    def collect_dataset(self):
        username = self.username_entry.get().strip()
        if not username:
            messagebox.showerror("–û—à–∏–±–∫–∞", "–í–≤–µ–¥–∏—Ç–µ –∏–º—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
            return

        self.dataset_path = os.path.join("Images", username)
        os.makedirs(self.dataset_path, exist_ok=True)

        self.face_counter = 0
        self.last_save_time = 0
        self.mode = "collect"

        self.cap = cv2.VideoCapture(0)
        self.status_label.config(text=f"–°–±–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞: {username}")

        self.update_camera_frame()

    def load_model(self):
        if os.path.exists("face_enc"):
            with open("face_enc", "rb") as f:
                self.data = pickle.loads(f.read())
            self.status_label.config(text="–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        else:
            self.data = None
            self.status_label.config(text="–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")


    def update_camera_frame(self):
        # –µ—Å–ª–∏ –Ω–∏—á–µ–≥–æ –Ω–µ –∑–∞–ø—É—â–µ–Ω–æ ‚Äî –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
        if self.mode == "idle":
            return

        ret, frame = self.cap.read()
        if not ret:
            return

        # ===============================
        # –†–ï–ñ–ò–ú –°–ë–û–†–ê –î–ê–¢–ê–°–ï–¢–ê (HAAR)
        # ===============================
        if self.mode == "collect":
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.faceCascade.detectMultiScale(
                gray,
                scaleFactor=1.3,
                minNeighbors=5,
                minSize=(60, 60)
            )

            for (x, y, w, h) in faces:
                # —Ä–∞–º–∫–∞ –ª–∏—Ü–∞
                cv2.rectangle(
                    frame,
                    (x, y),
                    (x + w, y + h),
                    (0, 255, 0),
                    2
                )

                # —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ª–∏—Ü —Å –∏–Ω—Ç–µ—Ä–≤–∞–ª–æ–º
                if time.time() - self.last_save_time >= self.save_interval:
                    face_img = frame[y:y + h, x:x + w]
                    img_path = os.path.join(
                        self.dataset_path,
                        f"{self.face_counter}.jpg"
                    )
                    cv2.imwrite(img_path, face_img)
                    self.face_counter += 1
                    self.last_save_time = time.time()

                # –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—á—ë—Ç—á–∏–∫–∞
                cv2.putText(
                    frame,
                    f"Saved: {self.face_counter}",
                    (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.9,
                    (0, 255, 0),
                    2
                )

        # ===================================
        # REAL-TIME –†–ê–°–ü–û–ó–ù–ê–í–ê–ù–ò–ï (DLIB)
        # ===================================
        elif self.mode == "realtime":
            rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

            boxes = face_recognition.face_locations(rgb, model="hog")
            encodings = face_recognition.face_encodings(rgb, boxes)

            for encoding, (top, right, bottom, left) in zip(encodings, boxes):
                name = "Unknown"

                matches = face_recognition.compare_faces(
                    self.data["encodings"],
                    encoding,
                    tolerance=0.5
                )

                if True in matches:
                    matched_idxs = [i for i, v in enumerate(matches) if v]
                    counts = {}

                    for i in matched_idxs:
                        person = self.data["names"][i]
                        counts[person] = counts.get(person, 0) + 1

                    name = max(counts, key=counts.get)

                # —Ä–∞–º–∫–∞ –ª–∏—Ü–∞
                cv2.rectangle(
                    frame,
                    (left, top),
                    (right, bottom),
                    (0, 255, 0),
                    2
                )

                # –∏–º—è
                cv2.putText(
                    frame,
                    name,
                    (left, top - 10),
                    cv2.FONT_HERSHEY_SIMPLEX,
                    0.8,
                    (0, 255, 0),
                    2
                )

        # ===============================
        # –û–¢–û–ë–†–ê–ñ–ï–ù–ò–ï –í TKINTER
        # ===============================
        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frame = cv2.resize(frame, (800, 600))

        imgtk = ImageTk.PhotoImage(Image.fromarray(frame))
        self.video_label.config(image=imgtk)
        self.video_label.image = imgtk

        # –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–∞–¥—Ä–∞
        self.root.after(10, self.update_camera_frame)



    def train_model(self):
        self.status_label.config(text="–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")

        process = subprocess.Popen(
            ["python", "face_recognition_from_dataset.py"],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE
        )

        def wait_and_load():
            process.wait()
            self.load_model()
            messagebox.showinfo("–ì–æ—Ç–æ–≤–æ", "–ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω–∞")

        threading.Thread(target=wait_and_load, daemon=True).start()


    def recognize_photo(self):
        if self.data is None:
            messagebox.showerror("–û—à–∏–±–∫–∞", "–ú–æ–¥–µ–ª—å –Ω–µ –æ–±—É—á–µ–Ω–∞")
            return
        
        file_path = filedialog.askopenfilename(
            filetypes=[("Images", "*.jpg *.png")]
        )
        if not file_path:
            return

        self.status_label.config(text="–†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –ø–æ —Ñ–æ—Ç–æ")

        # === –±–µ–∑–æ–ø–∞—Å–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ (—Ä–∞–±–æ—Ç–∞–µ—Ç —Å –∫–∏—Ä–∏–ª–ª–∏—Ü–µ–π) ===
        img_array = np.fromfile(file_path, dtype=np.uint8)
        image = cv2.imdecode(img_array, cv2.IMREAD_COLOR)

        if image is None:
            messagebox.showerror("–û—à–∏–±–∫–∞", "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
            return

        rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

        # === –ø–æ–∏—Å–∫ –ª–∏—Ü ===
        boxes = face_recognition.face_locations(rgb)
        encodings = face_recognition.face_encodings(rgb, boxes)

        # === —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ ===
        for encoding, (top, right, bottom, left) in zip(encodings, boxes):
            matches = face_recognition.compare_faces(self.data["encodings"], encoding)
            name = "Unknown"

            if True in matches:
                matchedIdxs = [i for i, b in enumerate(matches) if b]
                counts = {}

                for i in matchedIdxs:
                    counts[self.data["names"][i]] = counts.get(self.data["names"][i], 0) + 1

                name = max(counts, key=counts.get)

            cv2.rectangle(image, (left, top), (right, bottom), (0, 255, 0), 2)
            cv2.putText(image, name, (left, top - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)

        # === –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –±–ª–æ–∫–µ "–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ" ===
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        image = cv2.resize(image, (800, 600))

        imgtk = ImageTk.PhotoImage(Image.fromarray(image))
        self.video_label.config(image=imgtk)
        self.video_label.image = imgtk



    def start_realtime(self):
        if self.data is None:
            messagebox.showerror("–û—à–∏–±–∫–∞", "–°–Ω–∞—á–∞–ª–∞ –æ–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å")
            return

        self.mode = "realtime"
        self.cap = cv2.VideoCapture(0)
        self.status_label.config(text="Real-time —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ")
        self.update_camera_frame()


    


    def update_realtime_frame(self):
        if not self.running:
            return

        ret, frame = self.cap.read()
        if not ret:
            return

        rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        boxes = face_recognition.face_locations(rgb)
        encodings = face_recognition.face_encodings(rgb, boxes)

        for encoding, (top, right, bottom, left) in zip(encodings, boxes):
            matches = face_recognition.compare_faces(self.data["encodings"], encoding)
            name = "Unknown"

            if True in matches:
                matchedIdxs = [i for i, b in enumerate(matches) if b]
                counts = {}

                for i in matchedIdxs:
                    counts[self.data["names"][i]] = counts.get(self.data["names"][i], 0) + 1

                name = max(counts, key=counts.get)

            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)
            cv2.putText(frame, name, (left, top - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)

        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        frame = cv2.resize(frame, (800, 600))
        img = ImageTk.PhotoImage(Image.fromarray(frame))

        self.video_label.config(image=img)
        self.video_label.image = img

        self.root.after(10, self.update_realtime_frame)


    def stop_realtime(self):
        self.mode = "idle"
        if hasattr(self, "cap"):
            self.cap.release()
        self.status_label.config(text="–†–µ–∂–∏–º: –û–∂–∏–¥–∞–Ω–∏–µ")